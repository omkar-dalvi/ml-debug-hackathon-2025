{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3aed23c6-c95d-432c-ad83-bdafb2070219",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a06be021-ac6c-453d-9f11-b91246af2458",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amzecomdata\n",
      "globalmartmarketingdata\n",
      "inventorydata\n",
      "optimalchannel\n"
     ]
    }
   ],
   "source": [
    "# Replace with your details\n",
    "storage_account_name = \"\"\n",
    "storage_account_key = \"\"\n",
    "\n",
    "# Connect to ADLS\n",
    "service_client = DataLakeServiceClient(\n",
    "    account_url=f\"https://{storage_account_name}.dfs.core.windows.net\",\n",
    "    credential=storage_account_key,\n",
    "    api_version=\"2023-11-03\"  # Use the correct supported API version\n",
    ")\n",
    "\n",
    "# List Containers\n",
    "containers = service_client.list_file_systems()\n",
    "for container in containers:\n",
    "    print(container.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e869f3-0276-403f-b0ed-f51b949299d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_csv_from_blob(storage_account_name, container_name, file_name, storage_account_key=None):\n",
    "    \"\"\"\n",
    "    Read a CSV file from Azure Blob Storage using Python and return a Pandas DataFrame.\n",
    "\n",
    "    :param storage_account_name: Azure storage account name.\n",
    "    :param container_name: Blob container name.\n",
    "    :param file_name: Name of the file in the container.\n",
    "    :param storage_account_key: Storage account access key.\n",
    "    :return: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not storage_account_key:\n",
    "        # Try to get the key from environment variables if not provided\n",
    "        storage_account_key = os.environ.get('AZURE_STORAGE_KEY')\n",
    "        \n",
    "    if not storage_account_key:\n",
    "        raise ValueError(\"Storage account key must be provided either as a parameter or as an environment variable 'AZURE_STORAGE_KEY'\")\n",
    "    \n",
    "    try:\n",
    "        # Create a connection string\n",
    "        connection_string = f\"DefaultEndpointsProtocol=https;AccountName={storage_account_name};AccountKey={storage_account_key};EndpointSuffix=core.windows.net\"\n",
    "        \n",
    "        # Create the BlobServiceClient\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "        \n",
    "        # Get the container client\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        \n",
    "        # Get the blob client\n",
    "        blob_client = container_client.get_blob_client(file_name)\n",
    "        \n",
    "        # Download the blob content\n",
    "        download_stream = blob_client.download_blob()\n",
    "        \n",
    "        # Convert the content to a DataFrame\n",
    "        content = download_stream.readall()\n",
    "        df = pd.read_csv(io.BytesIO(content))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b7384f3-bca1-4d99-9d25-e47e03b44c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>week</th>\n",
       "      <th>sales_amount</th>\n",
       "      <th>base_price</th>\n",
       "      <th>final_price</th>\n",
       "      <th>promotion_type</th>\n",
       "      <th>facebook_spend</th>\n",
       "      <th>google ads_spend</th>\n",
       "      <th>influencer marketing_spend</th>\n",
       "      <th>instagram_spend</th>\n",
       "      <th>ooh_spend</th>\n",
       "      <th>print_spend</th>\n",
       "      <th>radio_spend</th>\n",
       "      <th>tv_spend</th>\n",
       "      <th>youtube_spend</th>\n",
       "      <th>facebook_ctr</th>\n",
       "      <th>google ads_ctr</th>\n",
       "      <th>influencer marketing_ctr</th>\n",
       "      <th>instagram_ctr</th>\n",
       "      <th>youtube_ctr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>13516527.77</td>\n",
       "      <td>101.830513</td>\n",
       "      <td>94.148539</td>\n",
       "      <td>Percentage Discount</td>\n",
       "      <td>1152.82</td>\n",
       "      <td>810.68</td>\n",
       "      <td>1122.12</td>\n",
       "      <td>707.48</td>\n",
       "      <td>11230.47</td>\n",
       "      <td>6214.43</td>\n",
       "      <td>6723.33</td>\n",
       "      <td>11311.42</td>\n",
       "      <td>703.13</td>\n",
       "      <td>3.047174</td>\n",
       "      <td>4.333516</td>\n",
       "      <td>2.471559</td>\n",
       "      <td>2.008197</td>\n",
       "      <td>2.116972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>95081753.02</td>\n",
       "      <td>101.830513</td>\n",
       "      <td>94.148539</td>\n",
       "      <td>Percentage Discount</td>\n",
       "      <td>7472.53</td>\n",
       "      <td>6973.85</td>\n",
       "      <td>7179.02</td>\n",
       "      <td>6834.33</td>\n",
       "      <td>11380.75</td>\n",
       "      <td>11069.60</td>\n",
       "      <td>9505.50</td>\n",
       "      <td>14004.01</td>\n",
       "      <td>6562.00</td>\n",
       "      <td>2.636847</td>\n",
       "      <td>2.732868</td>\n",
       "      <td>2.930657</td>\n",
       "      <td>3.354279</td>\n",
       "      <td>3.570124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>94804406.04</td>\n",
       "      <td>101.830513</td>\n",
       "      <td>94.148539</td>\n",
       "      <td>Percentage Discount</td>\n",
       "      <td>7204.29</td>\n",
       "      <td>7383.50</td>\n",
       "      <td>7185.08</td>\n",
       "      <td>6963.40</td>\n",
       "      <td>10270.30</td>\n",
       "      <td>8861.17</td>\n",
       "      <td>7836.04</td>\n",
       "      <td>14442.24</td>\n",
       "      <td>7318.19</td>\n",
       "      <td>2.679349</td>\n",
       "      <td>3.136116</td>\n",
       "      <td>2.879586</td>\n",
       "      <td>2.938546</td>\n",
       "      <td>3.776793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>94833974.28</td>\n",
       "      <td>101.830513</td>\n",
       "      <td>94.148539</td>\n",
       "      <td>Percentage Discount</td>\n",
       "      <td>7726.84</td>\n",
       "      <td>6522.20</td>\n",
       "      <td>7710.31</td>\n",
       "      <td>7479.41</td>\n",
       "      <td>8335.56</td>\n",
       "      <td>11601.91</td>\n",
       "      <td>6663.51</td>\n",
       "      <td>11917.89</td>\n",
       "      <td>7745.75</td>\n",
       "      <td>3.015955</td>\n",
       "      <td>3.836348</td>\n",
       "      <td>2.983655</td>\n",
       "      <td>2.858832</td>\n",
       "      <td>2.823088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-29</td>\n",
       "      <td>94806994.45</td>\n",
       "      <td>101.830513</td>\n",
       "      <td>94.148539</td>\n",
       "      <td>Percentage Discount</td>\n",
       "      <td>6987.22</td>\n",
       "      <td>6969.68</td>\n",
       "      <td>7094.25</td>\n",
       "      <td>7294.12</td>\n",
       "      <td>9575.21</td>\n",
       "      <td>7488.18</td>\n",
       "      <td>12158.00</td>\n",
       "      <td>6753.84</td>\n",
       "      <td>7044.42</td>\n",
       "      <td>2.744554</td>\n",
       "      <td>3.511152</td>\n",
       "      <td>2.338256</td>\n",
       "      <td>2.403631</td>\n",
       "      <td>3.019390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        week  ...  instagram_ctr  youtube_ctr\n",
       "0           0  2023-01-01  ...       2.008197     2.116972\n",
       "1           1  2023-01-08  ...       3.354279     3.570124\n",
       "2           2  2023-01-15  ...       2.938546     3.776793\n",
       "3           3  2023-01-22  ...       2.858832     2.823088\n",
       "4           4  2023-01-29  ...       2.403631     3.019390\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = read_csv_from_blob(storage_account_name=storage_account_name,\n",
    "                                      container_name=\"globalmartmarketingdata\", \n",
    "                                      file_name=\"PreProcessing_final_data.csv\",\n",
    "                                      storage_account_key=storage_account_key)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd6bbc48-8a23-46d0-aef2-fa7ff78a387b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select features for scaling and encoding\n",
    "numerical_features = ['sales_amount', 'base_price', 'final_price',\n",
    "                      'facebook_spend', 'google ads_spend', 'influencer marketing_spend',\n",
    "                      'instagram_spend', 'ooh_spend', 'print_spend', 'radio_spend',\n",
    "                      'tv_spend', 'youtube_spend', 'facebook_ctr', 'google ads_ctr',\n",
    "                      'influencer marketing_ctr', 'instagram_ctr', 'youtube_ctr']\n",
    "\n",
    "categorical_features = ['promotion_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94993d4e-533d-4bc6-98f1-3f4e3f73f548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_amount</th>\n",
       "      <th>base_price</th>\n",
       "      <th>final_price</th>\n",
       "      <th>facebook_spend</th>\n",
       "      <th>google ads_spend</th>\n",
       "      <th>influencer marketing_spend</th>\n",
       "      <th>instagram_spend</th>\n",
       "      <th>ooh_spend</th>\n",
       "      <th>print_spend</th>\n",
       "      <th>radio_spend</th>\n",
       "      <th>tv_spend</th>\n",
       "      <th>youtube_spend</th>\n",
       "      <th>facebook_ctr</th>\n",
       "      <th>google ads_ctr</th>\n",
       "      <th>influencer marketing_ctr</th>\n",
       "      <th>instagram_ctr</th>\n",
       "      <th>youtube_ctr</th>\n",
       "      <th>promotion_type_Buy One Get One Free</th>\n",
       "      <th>promotion_type_Percentage Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7.208240</td>\n",
       "      <td>-1.888843</td>\n",
       "      <td>-1.079989</td>\n",
       "      <td>-6.138594</td>\n",
       "      <td>-6.036483</td>\n",
       "      <td>-6.258867</td>\n",
       "      <td>-6.414760</td>\n",
       "      <td>0.452694</td>\n",
       "      <td>-1.329475</td>\n",
       "      <td>-0.967204</td>\n",
       "      <td>0.269455</td>\n",
       "      <td>-6.263100</td>\n",
       "      <td>0.408029</td>\n",
       "      <td>2.567653</td>\n",
       "      <td>-1.354243</td>\n",
       "      <td>-2.366897</td>\n",
       "      <td>-2.237695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.156877</td>\n",
       "      <td>-1.888843</td>\n",
       "      <td>-1.079989</td>\n",
       "      <td>0.671809</td>\n",
       "      <td>0.104967</td>\n",
       "      <td>0.342237</td>\n",
       "      <td>-0.124517</td>\n",
       "      <td>0.511463</td>\n",
       "      <td>0.407651</td>\n",
       "      <td>0.102746</td>\n",
       "      <td>1.192669</td>\n",
       "      <td>-0.319184</td>\n",
       "      <td>-0.548539</td>\n",
       "      <td>-0.479803</td>\n",
       "      <td>-0.315938</td>\n",
       "      <td>0.701320</td>\n",
       "      <td>1.459348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131833</td>\n",
       "      <td>-1.888843</td>\n",
       "      <td>-1.079989</td>\n",
       "      <td>0.382741</td>\n",
       "      <td>0.513173</td>\n",
       "      <td>0.348841</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.077207</td>\n",
       "      <td>-0.382501</td>\n",
       "      <td>-0.539284</td>\n",
       "      <td>1.342926</td>\n",
       "      <td>0.447983</td>\n",
       "      <td>-0.449456</td>\n",
       "      <td>0.287937</td>\n",
       "      <td>-0.431442</td>\n",
       "      <td>-0.246289</td>\n",
       "      <td>1.985146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.134503</td>\n",
       "      <td>-1.888843</td>\n",
       "      <td>-1.079989</td>\n",
       "      <td>0.945865</td>\n",
       "      <td>-0.345091</td>\n",
       "      <td>0.921263</td>\n",
       "      <td>0.537766</td>\n",
       "      <td>-0.679400</td>\n",
       "      <td>0.598106</td>\n",
       "      <td>-0.990209</td>\n",
       "      <td>0.477397</td>\n",
       "      <td>0.881749</td>\n",
       "      <td>0.335249</td>\n",
       "      <td>1.621101</td>\n",
       "      <td>-0.196076</td>\n",
       "      <td>-0.427986</td>\n",
       "      <td>-0.441227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132067</td>\n",
       "      <td>-1.888843</td>\n",
       "      <td>-1.079989</td>\n",
       "      <td>0.148817</td>\n",
       "      <td>0.100812</td>\n",
       "      <td>0.249850</td>\n",
       "      <td>0.347535</td>\n",
       "      <td>-0.194618</td>\n",
       "      <td>-0.873741</td>\n",
       "      <td>1.122828</td>\n",
       "      <td>-1.293211</td>\n",
       "      <td>0.170239</td>\n",
       "      <td>-0.297450</td>\n",
       "      <td>1.001963</td>\n",
       "      <td>-1.655725</td>\n",
       "      <td>-1.465558</td>\n",
       "      <td>0.058197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales_amount  ...  promotion_type_Percentage Discount\n",
       "0     -7.208240  ...                                 1.0\n",
       "1      0.156877  ...                                 1.0\n",
       "2      0.131833  ...                                 1.0\n",
       "3      0.134503  ...                                 1.0\n",
       "4      0.132067  ...                                 1.0\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_numerical_data = scaler.fit_transform(training_data[numerical_features])\n",
    "\n",
    "# Convert scaled numerical data to a DataFrame\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_features)\n",
    "\n",
    "# Step 2: Encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_categorical_data = encoder.fit_transform(training_data[categorical_features])\n",
    "\n",
    "# Get column names for encoded categorical features\n",
    "encoded_categorical_columns = encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "# Convert encoded categorical data to a DataFrame\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoded_categorical_columns)\n",
    "\n",
    "# Step 3: Combine scaled numerical data and encoded categorical data\n",
    "processed_df = pd.concat([scaled_numerical_df, encoded_categorical_df], axis=1)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "processed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe5e8b50-7db7-44ea-ba4e-733014b70bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales_amount                   1\n",
      "base_price                    27\n",
      "final_price                   27\n",
      "facebook_spend                24\n",
      "google ads_spend              19\n",
      "influencer marketing_spend    22\n",
      "instagram_spend               19\n",
      "ooh_spend                     28\n",
      "print_spend                   28\n",
      "radio_spend                   31\n",
      "tv_spend                      24\n",
      "youtube_spend                 24\n",
      "facebook_ctr                  24\n",
      "google ads_ctr                27\n",
      "influencer marketing_ctr      31\n",
      "instagram_ctr                 29\n",
      "youtube_ctr                   27\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any zero or negative values in the numerical columns\n",
    "print((processed_df[numerical_features] <= 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4913988-6ddb-4c20-890d-3e7178b0439f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Replace zero or negative values with a small positive value (e.g., 1e-6)\n",
    "processed_df[numerical_features] = processed_df[numerical_features].applymap(lambda x: max(x, 1e-6))\n",
    "\n",
    "# Apply log transformation to the target variable (sales_amount) and features (X)\n",
    "target_column = 'sales_amount'\n",
    "X = processed_df.drop(columns=[target_column])\n",
    "y = processed_df[target_column]\n",
    "\n",
    "# Apply log transformation (log-log regression)\n",
    "X_log = np.log1p(X)  # log(1 + x) to handle zero and negative values\n",
    "y_log = np.log1p(y)  # log(1 + y) to handle zero and negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f79e10b-b309-43df-bddc-1e80fcab73fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/05/09 08:08:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0932b5b8af6428996bb6f5310212920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run overjoyed-shrike-789 at: https://adb-5403682037278588.8.azuredatabricks.net/ml/experiments/1100311391393808/runs/88eaf56f92384a5ab5a589658235b7f7\n",
      "ðŸ§ª View experiment at: https://adb-5403682037278588.8.azuredatabricks.net/ml/experiments/1100311391393808\n"
     ]
    }
   ],
   "source": [
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Initialize Lasso model with a regularization parameter (alpha)\n",
    "    lasso_model = Lasso(alpha=0.1)  \n",
    "    \n",
    "    # Train the model on log-transformed features and target\n",
    "    lasso_model.fit(X_log, y_log)\n",
    "    \n",
    "    # Get the coefficients of the Lasso model\n",
    "    lasso_coefficients = pd.DataFrame({\n",
    "        'Feature': X_log.columns,\n",
    "        'Coefficient': lasso_model.coef_\n",
    "    }).sort_values(by='Coefficient', ascending=False)\n",
    "    \n",
    "    # Logging the model score \n",
    "    mlflow.log_metric(\"r_squared\", lasso_model.score(X_log, y_log))\n",
    "    \n",
    "    # Logging coefficients \n",
    "    for feature, coef in zip(lasso_coefficients['Feature'], lasso_coefficients['Coefficient']):\n",
    "        mlflow.log_metric(f\"coef_{feature}\", coef)  \n",
    "    \n",
    "    # Save the coefficients DataFrame as a CSV and log it as an artifact\n",
    "    coefficients_file_path = \"/tmp/lasso_coefficients.csv\"\n",
    "    lasso_coefficients.to_csv(coefficients_file_path, index=False)  # Saving DataFrame to CSV file\n",
    "    \n",
    "    # Log the CSV file as an artifact \n",
    "    mlflow.log_artifact(coefficients_file_path)  # Log the CSV file as an artifact\n",
    "    \n",
    "    # Logging the model \n",
    "    mlflow.log_param(\"model_type\", \"lasso\") \n",
    "    mlflow.sklearn.log_model(lasso_model, \"log_reg_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8b79a88-042b-454c-9b09-57db8ca4468b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created successfully: {'job_id': 635270909845232}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Databricks workspace URL and API token\n",
    "databricks_url = \"https://<your instance>.azuredatabricks.net\"\n",
    "api_token = \" \"\n",
    "\n",
    "# Define the path to your Python script in DBFS\n",
    "# This script will contain the inference logic using the trained model\n",
    "python_file_path = \"dbfs:/FileStore/path/to/inference.py\"  # Ensure the script is uploaded to DBFS\n",
    "\n",
    "# Job configuration for batch inference\n",
    "job_data = {\n",
    "    \"name\": \"Batch Inference Job\",\n",
    "    \"new_cluster\": {\n",
    "        \"spark_version\": \"15.4.x-cpu-ml-scala2.12\",  # Databricks runtime version with ML support\n",
    "        \"node_type_id\": \"Standard_DS3_v2\",  # Use the Standard_DS3_v2 cluster type\n",
    "        \"num_workers\": 2,  # Number of worker nodes (can adjust based on your requirements)\n",
    "        \"driver_memory\": \"14g\",  # 14 GB memory for the driver node\n",
    "        \"driver_cores\": 4,  # 4 cores for the driver node\n",
    "    },\n",
    "    \"libraries\": [\n",
    "        {\"pypi\": {\"package\": \"mlflow\"}},  # Install MLflow\n",
    "        {\"pypi\": {\"package\": \"scikit-learn\"}},  # Install scikit-learn\n",
    "    ],\n",
    "    \"spark_python_task\": {\n",
    "        \"python_file\": python_file_path,  # Path to the Python script that will handle batch inference\n",
    "        \"parameters\": [\"--input\", \"dbfs:/FileStore/path/to/input_data.csv\"]  # Path to the input data for inference\n",
    "    }\n",
    "}\n",
    "\n",
    "# Set headers for authentication\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# API endpoint to create a Databricks job\n",
    "endpoint = f\"{databricks_url}/api/2.0/jobs/create\"\n",
    "\n",
    "# Send POST request to create the job\n",
    "response = requests.post(endpoint, headers=headers, data=json.dumps(job_data))\n",
    "\n",
    "# Check if the job creation was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Job created successfully:\", response.json())\n",
    "else:\n",
    "    print(\"Error creating job:\", response.status_code, response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb8b040-8449-450b-ae9e-f65cfa27f2a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job run started successfully: {'run_id': 642193759589231, 'number_in_job': 642193759589231}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Databricks workspace URL and API token\n",
    "databricks_url = \"https://<your instance>.azuredatabricks.net\"\n",
    "api_token = \" \"\n",
    "\n",
    "# Job ID (replace with the actual Job ID from your job creation)\n",
    "job_id = \"635270909845232\"\n",
    "\n",
    "# Endpoint to trigger the job\n",
    "run_endpoint = f\"{databricks_url}/api/2.0/jobs/run-now\"\n",
    "\n",
    "# Payload to trigger the job\n",
    "run_payload = {\n",
    "    \"job_id\": job_id\n",
    "}\n",
    "\n",
    "# Send POST request to trigger the job\n",
    "run_response = requests.post(run_endpoint, headers={\n",
    "    \"Authorization\": f\"Bearer {api_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}, data=json.dumps(run_payload))\n",
    "\n",
    "# Check if the job run started successfully\n",
    "if run_response.status_code == 200:\n",
    "    print(\"Job run started successfully:\", run_response.json())\n",
    "else:\n",
    "    print(\"Error starting job run:\", run_response.status_code, run_response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the job, the predictions will be saved in the specified location, in this case:\n",
    "\n",
    "* Predictions: The batch inference results will be stored in /dbfs/FileStore/outputs/predictions.csv.\n",
    "\n",
    "You can download the predictions directly from DBFS or view them within Databricks. \n",
    "\n",
    "But in this case, this job is running blank and failed to do the same. "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "model_deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
